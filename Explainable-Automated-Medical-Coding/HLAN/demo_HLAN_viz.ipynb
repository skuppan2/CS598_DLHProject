{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLqbPZPoRPfU"
      },
      "source": [
        "# Colab-only Setup\n",
        "\n",
        "See `CS598DL4H/Setup.ipynb` for details of the mounted drive set up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP7HN8_lRaae",
        "outputId": "f3a2037e-dc5e-41f2-aeaf-a04e2717a8c7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI7kQpMFRjN3",
        "outputId": "3ffdb0fd-25bc-44b1-8739-5a1e0b149a39"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/My Drive/Illinois/DL4Healthcare/Project/CS598DL4H/Explainable-Automated-Medical-Coding/\n",
        "\n",
        "# Per https://colab.research.google.com/notebooks/tensorflow_version.ipynb, we shouldn't install tensorflow ourselves, here\n",
        "# Instead, we should just select the pre-installed version\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Moreover, it looks like the only thing needed that's not pre-installed, is tflearn, so just try that\n",
        "! pip install tflearn==0.5.0\n",
        "\n",
        "%cd HLAN/\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93r6cgOHTEAB",
        "outputId": "4a496944-73a6-4510-908f-24eb8b07c818"
      },
      "outputs": [],
      "source": [
        "# Bail out if not running on GPU\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgbwmFvuN3eK"
      },
      "source": [
        "# Explainable Automated Medical Coding\n",
        "An demo of using Hierarchical Label-wise Attention Network (HLAN) for explainable medical coding.\n",
        "\n",
        "The demo allows to input a discharge summary and then predict the ICD-9 codes related to it. \n",
        "* [0. Preparation](#0.-Preparation): import libraries\n",
        "* [1. Configuration](#1.-Configuration): setting hyper-parameters\n",
        "* [2. Data preprocessing](#2.-Data-preprocessing): (i) vocabulary building; (ii) sentence parsing, tokenisation\n",
        "* [3. Prediction and visualistion](#3.-Prediction-and-visualisation): (i) loading a pre-trained HLAN model (from the MIMIC-III dataset) to predict the top 50 ICD-9 codes; (ii) visualising the word-level and sentence-level attention scores for each assigned ICD-9 code.\n",
        "\n",
        "The program does not need GPU. On a CPU, it takes around 4s (seconds) to load the model to predict, and only a further 10s to visualise a batch (by default, 32) of discharge summaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_brJl6IN3eS"
      },
      "source": [
        "### 0. Preparation\n",
        "Import libraries to use for preprocessing data, loading a deep learning model, prediction, and visualisation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4egE-B7N3e5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
        "import warnings\n",
        "#do not show warning messages while importing tensorflow and functions that use numpy\n",
        "with warnings.catch_warnings():  \n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)  # or any {DEBUG, INFO, WARN, ERROR, FATAL}\n",
        "    #tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)  # or any {DEBUG, INFO, WARN, ERROR, FATAL}\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\",category=RuntimeWarning)\n",
        "    from data_util_gensim import load_data_multilabel_pre_split_for_pred,create_vocabulary,create_vocabulary_label_for_predict,get_label_sim_matrix,get_label_sub_matrix\n",
        "    from model_predict_util import preprocessing,viz_attention_scores,retrieve_icd_descs,output_to_file,display_for_qualitative_evaluation,display_for_qualitative_evaluation_per_label\n",
        "\n",
        "import time\n",
        "import pickle    \n",
        "import pandas as pd\n",
        "\n",
        "from HAN_model_dynamic import HAN    \n",
        "from tflearn.data_utils import pad_sequences\n",
        "from gensim.models import Word2Vec            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5oLWSBGN3e8"
      },
      "source": [
        "### 1. Configuration\n",
        "The setting and hyper-parameters for the HLAN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byxgn6KQN3e9"
      },
      "outputs": [],
      "source": [
        "#two key settings\n",
        "# (i) whether to input a document (otherwise, using a .txt file of documents, where each document occupies one line)\n",
        "to_input = True\n",
        "\n",
        "# (ii) the model checkpoint folder to load from - choose one from the options below\n",
        "#HLAN+LE+sent split trained on MIMIC-III-50\n",
        "ckpt_dir=\"../checkpoints/checkpoint_HAN_50_per_label_bs32_sent_split_LE/\";dataset = \"mimic3-ds-50\";batch_size = 32;per_label_attention=True;per_label_sent_only=False;sent_split=True #HLAN trained on MIMIC-III-50\n",
        "\n",
        "#HLAN+LE trained on MIMIC-III-50\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_50_per_label_bs32_LE/\";dataset = \"mimic3-ds-50\";batch_size = 32;per_label_attention=True;per_label_sent_only=False;sent_split=False #HLAN trained on MIMIC-III-50\n",
        "\n",
        "#HLAN+LE+sent split trained on MIMIC-III-shielding\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_shielding_th50_per_label_bs32_sent_split_LE/\";dataset = \"mimic3-ds-shielding-th50\";batch_size = 32;per_label_attention=True;per_label_sent_only=False;sent_split=True #HLAN trained on MIMIC-III-shielding\n",
        "\n",
        "#HLAN+LE trained on MIMIC-III-shielding\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_shielding_th50_per_label_bs32_LE/\";dataset = \"mimic3-ds-shielding-th50\";batch_size = 32;per_label_attention=True;per_label_sent_only=False;sent_split=False #HLAN trained on MIMIC-III-shielding\n",
        "\n",
        "#HA-GRU trained on MIMIC-III-50\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_50_per_label_sent_only_bs32_LE/\";dataset = \"mimic3-ds-50\";batch_size = 32;per_label_attention=True;per_label_sent_only=True;sent_split=False #HLAN trained on MIMIC-III-shielding\n",
        "\n",
        "#HA-GRU trained on MIMIC-III-shielding\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_shielding_th50_per_label_sent_only_bs32_LE/\";dataset = \"mimic3-ds-shielding-th50\";batch_size = 32;per_label_attention=True;per_label_sent_only=True;sent_split=False #HLAN trained on MIMIC-III-shielding\n",
        "\n",
        "#HAN+sent split trained on MIMIC-III\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_sent_split_LE/\";dataset = \"mimic3-ds\";batch_size = 128;per_label_attention=False;per_label_sent_only=False;sent_split=False #HAN trained on MIMIC-III\n",
        "\n",
        "#HAN trained on MIMIC-III\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_LE/\";dataset = \"mimic3-ds\";batch_size = 128;per_label_attention=False;per_label_sent_only=False;sent_split=True\n",
        "\n",
        "#HAN+sent split trained on MIMIC-III-50\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_50_LE/\";dataset = \"mimic3-ds-50\";batch_size = 128;per_label_attention=False;per_label_sent_only=False;sent_split=False\n",
        "\n",
        "#HAN+sent split trained on MIMIC-III-shielding\n",
        "#ckpt_dir=\"../checkpoints/checkpoint_HAN_shielding_th50_LE/\";dataset = \"mimic3-ds-shielding-th50\";batch_size = 128;per_label_attention=False;per_label_sent_only=False;sent_split=False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZYFwp_KN3e-"
      },
      "outputs": [],
      "source": [
        "#other settings and hyper-parameters\n",
        "word2vec_model_path = \"../embeddings/processed_full.w2v\"\n",
        "emb_model_path = \"../embeddings/word-mimic3-ds-label.model\" #using the one learned from the full label sets of mimic-iii discharge summaries\n",
        "label_embedding_model_path = \"../embeddings/code-emb-mimic3-tr-400.model\" # for label embedding initialisation (W_projection)\n",
        "label_embedding_model_path_per_label = \"../embeddings/code-emb-mimic3-tr-200.model\" # for label embedding initialisation (per_label context_vectors)\n",
        "kb_icd9 = \"../knowledge_bases/kb-icd-sub.csv\"\n",
        "\n",
        "gpu=True\n",
        "learning_rate = 0.01\n",
        "decay_steps = 6000\n",
        "decay_rate = 1.0\n",
        "sequence_length = 2500\n",
        "num_sentences = 100\n",
        "embed_size=100\n",
        "hidden_size=100\n",
        "is_training=False\n",
        "lambda_sim=0.0\n",
        "lambda_sub=0.0\n",
        "dynamic_sem=True\n",
        "dynamic_sem_l2=False\n",
        "multi_label_flag=True\n",
        "pred_threshold=0.5\n",
        "use_random_sampling=False\n",
        "miu_factor=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d25Zl1nMN3fC"
      },
      "source": [
        "### 2. Data preprocessing\n",
        "Part1: Loading label vocabulary and building word vocabulary from pre-trained embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrFv1NxKN3fD",
        "outputId": "a9b39126-527f-4744-846c-de6c3ba08aad",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#using gpu or not\n",
        "if not gpu: \n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  \n",
        "    \n",
        "#load the label list\n",
        "vocabulary_word2index_label,vocabulary_index2word_label = create_vocabulary_label_for_predict(name_scope=dataset + \"-HAN\") # keep a distinct name scope for each model and each dataset.\n",
        "if vocabulary_word2index_label == None:\n",
        "    print('_label_vocabulary.pik file unavailable')\n",
        "    sys.exit()\n",
        "\n",
        "#get the number of labels\n",
        "num_classes=len(vocabulary_word2index_label)\n",
        "\n",
        "#building the vocabulary list from the pre-trained word embeddings\n",
        "vocabulary_word2index, vocabulary_index2word = create_vocabulary(word2vec_model_path,name_scope=dataset + \"-HAN\")\n",
        "vocab_size = len(vocabulary_word2index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RApZay-EN3fF"
      },
      "source": [
        "Part2: Input a discharge summary and preprocess the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM748LvhN3fF",
        "outputId": "a7723f9c-3fb0-4187-ee85-11f137442d37",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#input or use files and preprocess a discharge summary\n",
        "if to_input:\n",
        "    print('Please input a discharge summary.');time.sleep(0.1) #sleep for proper display\n",
        "    report_raw = input(); preprocess = True\n",
        "\n",
        "    filename_to_predict = 'raw dis sum input.txt'\n",
        "    output_to_file(\"../datasets/%s\" % filename_to_predict,report_raw)\n",
        "else:\n",
        "    # directly load from file (each preprocessed document in a row)\n",
        "    if not sent_split:\n",
        "        #the sample document in the MIMIC-III-50\n",
        "        #filename_to_predict = 'sample MIMIC-III-50 test doc-24.txt'\n",
        "        #the 1730 testing documents for MIMIC-III-50\n",
        "        filename_to_predict= 'mimiciii_test_50_th0.txt'\n",
        "    else:   \n",
        "        #the sample sentence split document\n",
        "        #filename_to_predict='sample MIMIC-III-50 test doc-24 sent split.txt'\n",
        "        #the 1730 testing documents, all sentence-splitted, for MIMIC-III-50\n",
        "        filename_to_predict= 'mimiciii_test_50_sent_split_th0_for_HAN.txt'\n",
        "    preprocess = False # no further preprocessing if loading preprocessed documents\n",
        "    \n",
        "testing_data_path = \"../datasets/%s\" % filename_to_predict\n",
        "\n",
        "if preprocess:\n",
        "    #preprocess data (sentence parsing and tokenisation)\n",
        "    #this is only used for a *raw* discharge summary (one each time) and when to_input is set as true.\n",
        "    clinical_note_preprocessed_str = preprocessing(raw_clinical_note_file=testing_data_path,sent_parsing=sent_split,num_of_sen=100,num_of_sen_len=25) # tokenisation, padding, lower casing, sentence splitting\n",
        "    output_to_file('clinical_note_temp.txt',clinical_note_preprocessed_str) #load the preprocessed data\n",
        "    testX, testY = load_data_multilabel_pre_split_for_pred(vocabulary_word2index,vocabulary_word2index_label,data_path='clinical_note_temp.txt')\n",
        "else:\n",
        "    #this allows processing many preprocessed documents together, each in a row of the file in the testing_data_path\n",
        "    testX, testY = load_data_multilabel_pre_split_for_pred(vocabulary_word2index,vocabulary_word2index_label,data_path=testing_data_path)\n",
        "\n",
        "#padding to the maximum sequence length\n",
        "testX = pad_sequences(testX, maxlen=sequence_length, value=0.)  # padding to max length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-CSkmmxN3fs"
      },
      "source": [
        "### 3. Prediction and visualisation\n",
        "3.1 Load HLAN model to predict ICD-9 code\n",
        "\n",
        "<img src=\"https://github.com/dmcguire81/Explainable-Automated-Medical-Coding/blob/master/HLAN/HLAN-architecture.PNG?raw=1\" width=\"600\" height=\"300\" align=\"left\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvGT5G7zN3ft",
        "outputId": "5e0e4e5f-b4f2-4a8d-8a68-e44ea8e56fd4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#record the start time\n",
        "start_time = time.time()\n",
        "\n",
        "#create session.\n",
        "config=tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=False\n",
        "with tf.Session(config=config) as sess:\n",
        "    #Instantiate Model\n",
        "    model=HAN(num_classes, learning_rate, batch_size, decay_steps, decay_rate,sequence_length,num_sentences,vocab_size,embed_size,hidden_size,is_training,lambda_sim,lambda_sub,dynamic_sem,dynamic_sem_l2,per_label_attention,per_label_sent_only,multi_label_flag=multi_label_flag)\n",
        "    saver=tf.train.Saver(max_to_keep = 1) # only keep the latest model, here is the best model\n",
        "    if os.path.exists(ckpt_dir+\"checkpoint\"):\n",
        "        print(\"Restoring Variables from Checkpoint\")\n",
        "        saver.restore(sess,tf.train.latest_checkpoint(ckpt_dir))\n",
        "    else:\n",
        "        print(\"Can't find the checkpoint.going to stop\")\n",
        "        sys.exit()\n",
        "\n",
        "    #get prediction results and attention scores\n",
        "    if per_label_attention: # to do for per_label_sent_only\n",
        "        prediction_str = display_for_qualitative_evaluation_per_label(sess,model,testX,testY,batch_size,vocabulary_index2word,vocabulary_index2word_label,sequence_length,per_label_sent_only,num_sentences=num_sentences,threshold=pred_threshold,use_random_sampling=use_random_sampling,miu_factor=miu_factor) \n",
        "    else:\n",
        "        prediction_str = display_for_qualitative_evaluation(sess,model,testX,testY,batch_size,vocabulary_index2word,vocabulary_index2word_label,sequence_length=sequence_length,num_sentences=num_sentences,threshold=pred_threshold,use_random_sampling=use_random_sampling,miu_factor=miu_factor)\n",
        "\n",
        "#prediction_str #to display raw attention score outputs with predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7pcMNgzN3fu"
      },
      "source": [
        "3.2 Display and save the label-wise attention visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgZOCmu3N3fw",
        "outputId": "cb7195a5-eba5-4501-b56f-7a5fb5d33d65"
      },
      "outputs": [],
      "source": [
        "#get attention score and labels for visualisation\n",
        "list_doc_label_marks,list_doc_att_viz,dict_doc_pred = viz_attention_scores(prediction_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "ZzHAhVSdN3fw",
        "outputId": "ef300c86-96b3-47c2-df77-11bd7c6fd887"
      },
      "outputs": [],
      "source": [
        "if len(list_doc_att_viz) == 0: # if no ICD code assigned for the document.\n",
        "    print('No ICD code predicted for this document.')    \n",
        "else:    \n",
        "    for ind, (doc_label_mark, doc_att_viz) in enumerate(zip(list_doc_label_marks,list_doc_att_viz)):\n",
        "        # retrieve and display ICD-9 codes and descriptions \n",
        "        doc_label_mark_ele_list = doc_label_mark.split('-')\n",
        "        if len(doc_label_mark_ele_list)==2: # HAN model, same visualisation for all codes\n",
        "            doc_label_mark_without_code = '-'.join(doc_label_mark_ele_list[:3])\n",
        "            print(doc_label_mark_without_code)\n",
        "            filename = 'att-%s.xlsx' % (doc_label_mark[:len(doc_label_mark)-1])     \n",
        "            predictions = dict_doc_pred[doc_label_mark_without_code]\n",
        "            predictions = predictions.split('labels:')[0]\n",
        "            ICD_9_codes = predictions.split(' ')[1:]\n",
        "            print('Predicted code list:')\n",
        "            for ICD_9_code in ICD_9_codes:\n",
        "                # retrieve the short title and the long title of this ICD-9 code\n",
        "                _, long_tit,code_type = retrieve_icd_descs(ICD_9_code)\n",
        "                print(code_type,'code:',ICD_9_code,'(',long_tit,')')\n",
        "        else: # HLAN or HA-GRU, a different visualisation for each label\n",
        "            ICD_9_code = doc_label_mark_ele_list[3] # retrieve the predicted ICD-9 code\n",
        "            ICD_9_code = ICD_9_code[:len(ICD_9_code)-1] # drop the trailing colon\n",
        "            short_tit, long_tit,code_type = retrieve_icd_descs(ICD_9_code) # retrieve the short title and the long title of this ICD-9 code\n",
        "            doc_label_mark_without_code = '-'.join(doc_label_mark_ele_list[:3])\n",
        "            print(doc_label_mark_without_code,'to predict %s code' % code_type,ICD_9_code,'(%s)' % (long_tit))\n",
        "            filename = 'att-%s(%s).xlsx' % (doc_label_mark[:len(doc_label_mark)-1],short_tit) #do not include the colon in the last char\n",
        "            filename = filename.replace('/','').replace('<','').replace('>','') # avoid slash / or <, > signs in the filename\n",
        "        \n",
        "        # export the visualisation to an Excel sheet\n",
        "        filename = os.sep.join(['..', 'explanations', filename]) # put the files under the ../explanations/ folder.\n",
        "        doc_att_viz.set_properties(**{'font-size': '9pt'})\\\n",
        "                   .to_excel(filename, engine='openpyxl')\n",
        "        print('Visualisation below saved to %s.' % filename) \n",
        "        \n",
        "        # reset the font for the display below\n",
        "        doc_att_viz.set_properties(**{'font-size': '5pt'})\n",
        "        display(doc_att_viz)\n",
        "        \n",
        "        #display the prediction when the label-wise visualisations for the document end\n",
        "        if ind!=len(list_doc_label_marks)-1:\n",
        "            #this is not the last doc label mark\n",
        "            if list_doc_label_marks[ind+1][:len(doc_label_mark_without_code)] != doc_label_mark_without_code:                \n",
        "                #the next doc label mark is not the current one\n",
        "                print(dict_doc_pred[doc_label_mark_without_code])\n",
        "                #print('Visualisation for %s ended.\\n' % doc_label_mark_without_code)\n",
        "        else:\n",
        "            #this is the last doc label mark\n",
        "            print(dict_doc_pred[doc_label_mark_without_code])                                   \n",
        "            #print('Visualisation for %s ended.\\n' % doc_label_mark_without_code)\n",
        "\n",
        "print(\"--- The prediction and visualisation took %s seconds ---\" % (time.time() - start_time))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "demo_HLAN_viz.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
